import os.path as osp
import glob
import numpy as np
import cv2
import torch


def read_img(img_path):
    """Read an image from a given image path
    Args:
        img_path (str): image path
    Returns:
        img (Numpy): size (H, W, C), BGR, [0, 1]
    """
    img = cv2.imread(img_path)
    img = img.astype(np.float32) / 255.0
    return img


def read_img_seq(img_folder_path):
    """Read a sequence of images from a given folder path
    Args:
        img_folder_path (str): image folder path
    Returns:
        imgs (Tensor): size (T, C, H, W), RGB, [0, 1]
    """
    img_path_l = sorted(glob.glob(osp.join(img_folder_path, "*")))
    img_l = [read_img(v) for v in img_path_l]
    # stack to Torch tensor
    imgs = np.stack(img_l, axis=0)
    imgs = imgs[:, :, :, [2, 1, 0]]
    imgs = torch.from_numpy(
        np.ascontiguousarray(np.transpose(imgs, (0, 3, 1, 2)))
    ).float()
    return imgs


def index_generation(crt_i, max_n, N, padding="reflection"):
    """Generate an index list for reading N frames from a sequence of images
    Args:
        crt_i (int): current center index
        max_n (int): max number of the sequence of images (calculated from 1)
        N (int): reading N frames
        padding (str): padding mode, one of replicate | reflection | new_info | circle
            Example: crt_i = 0, N = 5
            replicate: [0, 0, 0, 1, 2]
            reflection: [2, 1, 0, 1, 2]
            new_info: [4, 3, 0, 1, 2]
            circle: [3, 4, 0, 1, 2]
    Returns:
        return_l (list [int]): a list of indexes
    """
    max_n = max_n - 1
    n_pad = N // 2
    return_l = []

    for i in range(crt_i - n_pad, crt_i + n_pad + 1):
        if i < 0:
            if padding == "replicate":
                add_idx = 0
            elif padding == "reflection":
                add_idx = -i
            elif padding == "new_info":
                add_idx = (crt_i + n_pad) + (-i)
            elif padding == "circle":
                add_idx = N + i
            else:
                raise ValueError("Wrong padding mode")
        elif i > max_n:
            if padding == "replicate":
                add_idx = max_n
            elif padding == "reflection":
                add_idx = max_n * 2 - i
            elif padding == "new_info":
                add_idx = (crt_i - n_pad) - (i - max_n)
            elif padding == "circle":
                add_idx = i - N
            else:
                raise ValueError("Wrong padding mode")
        else:
            add_idx = i
        return_l.append(add_idx)
    return return_l


def single_forward(model, inp):
    """PyTorch model forward (single test), it is just a simple warpper
    Args:
        model (PyTorch model)
        inp (Tensor): inputs defined by the model
    Returns:
        output (Tensor): outputs of the model. float, in CPU
    """
    with torch.no_grad():
        model_output = model(inp)
        if isinstance(model_output, list) or isinstance(model_output, tuple):
            output = model_output[0]
        else:
            output = model_output
    output = output.data.float().cpu()
    return output


def flipx4_forward(model, inp):
    """Flip testing with X4 self ensemble, i.e., normal, flip H, flip W, flip H and W
    Args:
        model (PyTorch model)
        inp (Tensor): inputs defined by the model
    Returns:
        output (Tensor): outputs of the model. float, in CPU
    """
    # normal
    output_f = single_forward(model, inp)

    # flip W
    output = single_forward(model, torch.flip(inp, (-1,)))
    output_f = output_f + torch.flip(output, (-1,))
    # flip H
    output = single_forward(model, torch.flip(inp, (-2,)))
    output_f = output_f + torch.flip(output, (-2,))
    # flip both H and W
    output = single_forward(model, torch.flip(inp, (-2, -1)))
    output_f = output_f + torch.flip(output, (-2, -1))

    return output_f / 4


def crop_border(img_list, crop_border):
    """Crop borders of images
    Args:
        img_list (list [Numpy]): HWC
        crop_border (int): crop border for each end of height and weight
    Returns:
        (list [Numpy]): cropped image list
    """
    if crop_border == 0:
        return img_list
    else:
        return [v[crop_border:-crop_border, crop_border:-crop_border] for v in img_list]
